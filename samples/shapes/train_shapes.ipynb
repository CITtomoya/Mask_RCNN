{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Train on Shapes Dataset\n",
    "\n",
    "\n",
    "This notebook shows how to train Mask R-CNN on your own dataset. To keep things simple we use a synthetic dataset of shapes (squares, triangles, and circles) which enables fast training. You'd still need a GPU, though, because the network backbone is a Resnet101, which would be too slow to train on a CPU. On a GPU, you can start to get okay-ish results in a few minutes, and good results in less than an hour.\n",
    "\n",
    "The code of the *Shapes* dataset is included below. It generates images on the fly, so it doesn't require downloading any data. And it can generate images of any size, so we pick a small image size to train faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "# Download COCO trained weights from Releases if needed\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     8\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.7\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 8\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  128\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  128\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [128 128   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           shapes\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           32\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               5\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"shapes\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 8\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 3  # background + 3 shapes\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 128\n",
    "    IMAGE_MAX_DIM = 128\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a synthetic dataset\n",
    "\n",
    "Extend the Dataset class and add a method to load the shapes dataset, `load_shapes()`, and override the following methods:\n",
    "\n",
    "* load_image()\n",
    "* load_mask()\n",
    "* image_reference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    \"\"\"Generates the shapes synthetic dataset. The dataset consists of simple\n",
    "    shapes (triangles, squares, circles) placed randomly on a blank surface.\n",
    "    The images are generated on the fly. No file access required.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_shapes(self, count, height, width):\n",
    "        \"\"\"Generate the requested number of synthetic images.\n",
    "        count: number of images to generate.\n",
    "        height, width: the size of the generated images.\n",
    "        \"\"\"\n",
    "        # Add classes\n",
    "        self.add_class(\"shapes\", 1, \"square\")\n",
    "        self.add_class(\"shapes\", 2, \"circle\")\n",
    "        self.add_class(\"shapes\", 3, \"triangle\")\n",
    "\n",
    "        # Add images\n",
    "        # Generate random specifications of images (i.e. color and\n",
    "        # list of shapes sizes and locations). This is more compact than\n",
    "        # actual images. Images are generated on the fly in load_image().\n",
    "        for i in range(count):\n",
    "            bg_color, shapes = self.random_image(height, width)\n",
    "            self.add_image(\"shapes\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=bg_color, shapes=shapes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Generate an image from the specs of the given image ID.\n",
    "        Typically this function loads the image from a file, but\n",
    "        in this case it generates the image on the fly from the\n",
    "        specs in image_info.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        bg_color = np.array(info['bg_color']).reshape([1, 1, 3])\n",
    "        image = np.ones([info['height'], info['width'], 3], dtype=np.uint8)\n",
    "        image = image * bg_color.astype(np.uint8)\n",
    "        for shape, color, dims in info['shapes']:\n",
    "            image = self.draw_shape(image, shape, dims, color)\n",
    "        return image\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the shapes data of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"shapes\":\n",
    "            return info[\"shapes\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for shapes of the given image ID.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        shapes = info['shapes']\n",
    "        count = len(shapes)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "        for i, (shape, _, dims) in enumerate(info['shapes']):\n",
    "            mask[:, :, i:i+1] = self.draw_shape(mask[:, :, i:i+1].copy(),\n",
    "                                                shape, dims, 1)\n",
    "        # Handle occlusions\n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        # Map class names to class IDs.\n",
    "        class_ids = np.array([self.class_names.index(s[0]) for s in shapes])\n",
    "        return mask.astype(np.bool), class_ids.astype(np.int32)\n",
    "\n",
    "    def draw_shape(self, image, shape, dims, color):\n",
    "        \"\"\"Draws a shape from the given specs.\"\"\"\n",
    "        # Get the center x, y and the size s\n",
    "        x, y, s = dims\n",
    "        if shape == 'square':\n",
    "            cv2.rectangle(image, (x-s, y-s), (x+s, y+s), color, -1)\n",
    "        elif shape == \"circle\":\n",
    "            cv2.circle(image, (x, y), s, color, -1)\n",
    "        elif shape == \"triangle\":\n",
    "            points = np.array([[(x, y-s),\n",
    "                                (x-s/math.sin(math.radians(60)), y+s),\n",
    "                                (x+s/math.sin(math.radians(60)), y+s),\n",
    "                                ]], dtype=np.int32)\n",
    "            cv2.fillPoly(image, points, color)\n",
    "        return image\n",
    "\n",
    "    def random_shape(self, height, width):\n",
    "        \"\"\"Generates specifications of a random shape that lies within\n",
    "        the given height and width boundaries.\n",
    "        Returns a tuple of three valus:\n",
    "        * The shape name (square, circle, ...)\n",
    "        * Shape color: a tuple of 3 values, RGB.\n",
    "        * Shape dimensions: A tuple of values that define the shape size\n",
    "                            and location. Differs per shape type.\n",
    "        \"\"\"\n",
    "        # Shape\n",
    "        shape = random.choice([\"square\", \"circle\", \"triangle\"])\n",
    "        # Color\n",
    "        color = tuple([random.randint(0, 255) for _ in range(3)])\n",
    "        # Center x, y\n",
    "        buffer = 20\n",
    "        y = random.randint(buffer, height - buffer - 1)\n",
    "        x = random.randint(buffer, width - buffer - 1)\n",
    "        # Size\n",
    "        s = random.randint(buffer, height//4)\n",
    "        return shape, color, (x, y, s)\n",
    "\n",
    "    def random_image(self, height, width):\n",
    "        \"\"\"Creates random specifications of an image with multiple shapes.\n",
    "        Returns the background color of the image and a list of shape\n",
    "        specifications that can be used to draw the image.\n",
    "        \"\"\"\n",
    "        # Pick random background color\n",
    "        bg_color = np.array([random.randint(0, 255) for _ in range(3)])\n",
    "        # Generate a few random shapes and record their\n",
    "        # bounding boxes\n",
    "        shapes = []\n",
    "        boxes = []\n",
    "        N = random.randint(1, 4)\n",
    "        for _ in range(N):\n",
    "            shape, color, dims = self.random_shape(height, width)\n",
    "            shapes.append((shape, color, dims))\n",
    "            x, y, s = dims\n",
    "            boxes.append([y-s, x-s, y+s, x+s])\n",
    "        # Apply non-max suppression wit 0.3 threshold to avoid\n",
    "        # shapes covering each other\n",
    "        keep_ixs = utils.non_max_suppression(np.array(boxes), np.arange(N), 0.3)\n",
    "        shapes = [s for i, s in enumerate(shapes) if i in keep_ixs]\n",
    "        return bg_color, shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "dataset_train = ShapesDataset()\n",
    "dataset_train.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = ShapesDataset()\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display random samples\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2139: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\tensorflow_core\\python\\ops\\array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\\mrcnn\\model.py:553: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\\mrcnn\\utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\mask_rcnn-2.1-py3.6.egg\\mrcnn\\model.py:600: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    }
   ],
   "source": [
    "# Create model in training mode\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                          model_dir=MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which weights to start with?\n",
    "init_with = \"coco\"  # imagenet, coco, or last\n",
    "\n",
    "if init_with == \"imagenet\":\n",
    "    model.load_weights(model.get_imagenet_weights(), by_name=True)\n",
    "elif init_with == \"coco\":\n",
    "    # Load weights trained on MS COCO, but skip layers that\n",
    "    # are different due to the different number of classes\n",
    "    # See README for instructions to download the COCO weights\n",
    "    model.load_weights(COCO_MODEL_PATH, by_name=True,\n",
    "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "elif init_with == \"last\":\n",
    "    # Load the last model you trained and continue training\n",
    "    model.load_weights(model.find_last(), by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Train in two stages:\n",
    "1. Only the heads. Here we're freezing all the backbone layers and training only the randomly initialized layers (i.e. the ones that we didn't use pre-trained weights from MS COCO). To train only the head layers, pass `layers='heads'` to the `train()` function.\n",
    "\n",
    "2. Fine-tune all layers. For this simple example it's not necessary, but we're including it to show the process. Simply pass `layers=\"all` to train all layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: I:\\Mask_RCNN\\logs\\shapes20200309T2234\\mask_rcnn_shapes_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l:\\python3.6.8\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "l:\\python3.6.8\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "l:\\python3.6.8\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From l:\\python3.6.8\\lib\\site-packages\\keras\\callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/1\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 1.9969 - rpn_class_loss: 0.0312 - rpn_bbox_loss: 0.6379 - mrcnn_class_loss: 0.4237 - mrcnn_bbox_loss: 0.4071 - mrcnn_mask_loss: 0.4970"
     ]
    }
   ],
   "source": [
    "# Train the head branches\n",
    "# Passing layers=\"heads\" freezes all layers except the head\n",
    "# layers. You can also pass a regular expression to select\n",
    "# which layers to train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE, \n",
    "            epochs=1, \n",
    "            layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fine tune all layers\n",
    "# Passing layers=\"all\" trains all layers. You can also \n",
    "# pass a regular expression to select which layers to\n",
    "# train by name pattern.\n",
    "model.train(dataset_train, dataset_val, \n",
    "            learning_rate=config.LEARNING_RATE / 10,\n",
    "            epochs=2, \n",
    "            layers=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save weights\n",
    "# Typically not needed because callbacks save after every epoch\n",
    "# Uncomment to save manually\n",
    "# model_path = os.path.join(MODEL_DIR, \"mask_rcnn_shapes.h5\")\n",
    "# model.keras_model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "# Recreate the model in inference mode\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "model_path = model.find_last()\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a random image\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "log(\"original_image\", original_image)\n",
    "log(\"image_meta\", image_meta)\n",
    "log(\"gt_class_id\", gt_class_id)\n",
    "log(\"gt_bbox\", gt_bbox)\n",
    "log(\"gt_mask\", gt_mask)\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=get_ax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inference_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1202a181ecc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Load image and ground truth data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_class_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_bbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgt_mask\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         modellib.load_image_gt(dataset_val, inference_config,\n\u001b[0m\u001b[0;32m      9\u001b[0m                                image_id, use_mini_mask=False)\n\u001b[0;32m     10\u001b[0m     \u001b[0mmolded_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodellib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmold_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minference_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inference_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5\n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
